# Milvus StorageV2 数据压缩与编码机制

## 1. 概述

StorageV2 采用多层次的数据压缩和编码策略，通过 Apache Arrow 格式、ZSTD 压缩算法、以及自定义编码方案，实现了高效的数据存储和传输。整个系统在保证数据完整性的同时，最大化存储效率和查询性能。

## 2. 压缩架构设计

### 2.1 分层压缩架构

```
┌─────────────────────────────────────────────────────┐
│                  Application Data                  │
│           (Insert/Query/Index Data)               │
├─────────────────────────────────────────────────────┤
│                   Data Encoding                    │
│  ┌─────────────────┐    ┌─────────────────────────┐  │
│  │  Value Encoding │    │   Schema Encoding      │  │
│  │  (Type-specific)│    │   (Metadata)           │  │
│  └─────────────────┘    └─────────────────────────┘  │
├─────────────────────────────────────────────────────┤
│                Arrow Format Layer                  │
│  ┌─────────────────┐    ┌─────────────────────────┐  │
│  │  Columnar Data  │    │   Memory Layout        │  │
│  │   Organization  │    │    Optimization        │  │
│  └─────────────────┘    └─────────────────────────┘  │
├─────────────────────────────────────────────────────┤
│                Compression Layer                   │
│  ┌─────────────────┐    ┌─────────────────────────┐  │
│  │   ZSTD Codec    │    │   LZ4 / GZIP / SNAPPY  │  │
│  │  (Default)      │    │    (Alternative)       │  │
│  └─────────────────┘    └─────────────────────────┘  │
├─────────────────────────────────────────────────────┤
│                 Storage Backend                    │
│           (Local/MinIO/Cloud Storage)             │
└─────────────────────────────────────────────────────┘
```

### 2.2 核心组件

#### 2.2.1 压缩编解码器接口
```go
type Codec interface {
    // 编码数据
    Encode(dst, src []byte) []byte
    EncodeLevel(dst, src []byte, level int) []byte
    
    // 解码数据
    Decode(dst, src []byte) []byte
    
    // I/O 接口
    NewReader(r io.Reader) io.ReadCloser
    NewWriter(w io.Writer) io.WriteCloser
    NewWriterLevel(w io.Writer, level int) (io.WriteCloser, error)
    
    // 压缩边界计算
    CompressBound(len int64) int64
}
```

#### 2.2.2 数据序列化接口
```go
type SerDe[T any] struct {
    // 反序列化函数
    deserialize func(arrow.Array, int, bool) (any, bool)
    
    // 序列化函数
    serialize func(array.Builder, any) bool
}

type RecordWriter interface {
    Write(r Record) error
    GetWrittenUncompressed() uint64  // 获取未压缩大小
    Close() error
}
```

## 3. ZSTD 压缩实现

### 3.1 ZSTD 编解码器

#### 3.1.1 编解码器结构
```go
type zstdCodec struct{}

var (
    enc         *zstd.Encoder    // 全局编码器
    dec         *zstd.Decoder    // 全局解码器
    initEncoder sync.Once        // 编码器初始化
    initDecoder sync.Once        // 解码器初始化
)
```

#### 3.1.2 编码器初始化
```go
func getencoder() *zstd.Encoder {
    initEncoder.Do(func() {
        // 创建零帧编码器，减少开销
        enc, _ = zstd.NewWriter(nil, zstd.WithZeroFrames(true))
    })
    return enc
}

func getdecoder() *zstd.Decoder {
    initDecoder.Do(func() {
        dec, _ = zstd.NewReader(nil)
    })
    return dec
}
```

### 3.2 压缩实现

#### 3.2.1 基础压缩
```go
func (zstdCodec) Encode(dst, src []byte) []byte {
    return getencoder().EncodeAll(src, dst[:0])
}

func (zstdCodec) Decode(dst, src []byte) []byte {
    dst, err := getdecoder().DecodeAll(src, dst[:0])
    if err != nil {
        panic(err)
    }
    return dst
}
```

#### 3.2.2 分级压缩
```go
func (z zstdCodec) EncodeLevel(dst, src []byte, level int) []byte {
    var compressLevel zstd.EncoderLevel
    
    if level == compress.DefaultCompressionLevel {
        compressLevel = zstd.SpeedDefault
    } else {
        compressLevel = zstd.EncoderLevelFromZstd(level)
    }
    
    // 创建指定级别的编码器
    enc, _ := zstd.NewWriter(nil, 
        zstd.WithZeroFrames(true), 
        zstd.WithEncoderLevel(compressLevel), 
        zstd.WithEncoderConcurrency(z.getConcurrency()))
        
    return enc.EncodeAll(src, dst[:0])
}
```

#### 3.2.3 并发控制
```go
func (zstdCodec) getConcurrency() int {
    // 从配置获取并发数
    concurrent := paramtable.Get().CommonCfg.StorageZstdConcurrency.GetAsInt()
    if concurrent <= 0 {
        return hardware.GetCPUNum()
    }
    return concurrent
}
```

### 3.3 I/O 包装器

#### 3.3.1 Reader 包装
```go
type zstdcloser struct {
    *zstd.Decoder
}

func (z *zstdcloser) Close() error {
    z.Decoder.Close()
    return nil
}

func (zstdCodec) NewReader(r io.Reader) io.ReadCloser {
    ret, _ := zstd.NewReader(r)
    return &zstdcloser{ret}
}
```

#### 3.3.2 Writer 包装
```go
func (zstdCodec) NewWriter(w io.Writer) io.WriteCloser {
    ret, _ := zstd.NewWriter(w)
    return ret
}

func (z zstdCodec) NewWriterLevel(w io.Writer, level int) (io.WriteCloser, error) {
    var compressLevel zstd.EncoderLevel
    
    if level == compress.DefaultCompressionLevel {
        compressLevel = zstd.SpeedDefault
    } else {
        compressLevel = zstd.EncoderLevelFromZstd(level)
    }
    
    return zstd.NewWriter(w, 
        zstd.WithEncoderLevel(compressLevel), 
        zstd.WithEncoderConcurrency(z.getConcurrency()))
}
```

### 3.4 压缩边界计算

#### 3.4.1 边界估算
```go
func (zstdCodec) CompressBound(len int64) int64 {
    // 基于 ZSTD_COMPRESSBOUND 公式
    extra := ((128 << 10) - len) >> 11
    if len >= (128 << 10) {
        extra = 0
    }
    return len + (len >> 8) + extra
}
```

## 4. 数据序列化机制

### 4.1 类型特定编码

#### 4.1.1 布尔类型编码
```go
var boolSerDe = SerDe[bool]{
    deserialize: func(a arrow.Array, i int, shouldCopy bool) (any, bool) {
        if a.IsNull(i) {
            return nil, false
        }
        arr := a.(*array.Boolean)
        return arr.Value(i), true
    },
    
    serialize: func(b array.Builder, v any) bool {
        builder := b.(*array.BooleanBuilder)
        if v == nil {
            builder.AppendNull()
            return false
        }
        val, ok := v.(bool)
        if !ok {
            builder.AppendNull()
            return false
        }
        builder.Append(val)
        return true
    },
}
```

#### 4.1.2 整数类型编码
```go
var int64SerDe = SerDe[int64]{
    deserialize: func(a arrow.Array, i int, shouldCopy bool) (any, bool) {
        if a.IsNull(i) {
            return nil, false
        }
        arr := a.(*array.Int64)
        return arr.Value(i), true
    },
    
    serialize: func(b array.Builder, v any) bool {
        builder := b.(*array.Int64Builder)
        if v == nil {
            builder.AppendNull()
            return false
        }
        
        var val int64
        switch v := v.(type) {
        case int64:
            val = v
        case int32:
            val = int64(v)
        case int:
            val = int64(v)
        default:
            builder.AppendNull()
            return false
        }
        
        builder.Append(val)
        return true
    },
}
```

#### 4.1.3 字符串类型编码
```go
var stringSerDe = SerDe[string]{
    deserialize: func(a arrow.Array, i int, shouldCopy bool) (any, bool) {
        if a.IsNull(i) {
            return nil, false
        }
        arr := a.(*array.String)
        val := arr.Value(i)
        
        // 根据需要进行深拷贝
        if shouldCopy {
            return string([]byte(val)), true
        }
        return val, true
    },
    
    serialize: func(b array.Builder, v any) bool {
        builder := b.(*array.StringBuilder)
        if v == nil {
            builder.AppendNull()
            return false
        }
        
        str, ok := v.(string)
        if !ok {
            // 尝试转换其他类型
            if stringer, ok := v.(fmt.Stringer); ok {
                str = stringer.String()
            } else {
                builder.AppendNull()
                return false
            }
        }
        
        builder.Append(str)
        return true
    },
}
```

#### 4.1.4 向量类型编码
```go
var floatVectorSerDe = SerDe[[]float32]{
    deserialize: func(a arrow.Array, i int, shouldCopy bool) (any, bool) {
        if a.IsNull(i) {
            return nil, false
        }
        
        arr := a.(*array.List)
        slice := arr.ListValues()
        start, end := arr.ValueOffsets(i)
        
        floatArr := slice.(*array.Float32)
        vector := make([]float32, end-start)
        
        for j := start; j < end; j++ {
            vector[j-start] = floatArr.Value(int(j))
        }
        
        return vector, true
    },
    
    serialize: func(b array.Builder, v any) bool {
        builder := b.(*array.ListBuilder)
        if v == nil {
            builder.AppendNull()
            return false
        }
        
        vector, ok := v.([]float32)
        if !ok {
            builder.AppendNull()
            return false
        }
        
        builder.Append(true)
        valueBuilder := builder.ValueBuilder().(*array.Float32Builder)
        for _, val := range vector {
            valueBuilder.Append(val)
        }
        
        return true
    },
}
```

### 4.2 序列化流程控制

#### 4.2.1 Record 序列化
```go
func SerializeRecord(record Record, schema *schemapb.CollectionSchema) ([]byte, error) {
    // 1. 转换为 Arrow Record
    arrowRecord, err := ConvertToArrowRecord(record, schema)
    if err != nil {
        return nil, err
    }
    defer arrowRecord.Release()
    
    // 2. 序列化为 Arrow IPC 格式
    var buf bytes.Buffer
    writer := ipc.NewWriter(&buf, ipc.WithSchema(arrowRecord.Schema()))
    defer writer.Close()
    
    if err := writer.Write(arrowRecord); err != nil {
        return nil, err
    }
    
    // 3. 压缩数据
    compressed := zstdCodec{}.Encode(nil, buf.Bytes())
    
    return compressed, nil
}
```

#### 4.2.2 Record 反序列化
```go
func DeserializeRecord(data []byte, schema *schemapb.CollectionSchema) (Record, error) {
    // 1. 解压缩数据
    decompressed := zstdCodec{}.Decode(nil, data)
    
    // 2. 从 Arrow IPC 格式反序列化
    reader, err := ipc.NewReader(bytes.NewReader(decompressed))
    if err != nil {
        return nil, err
    }
    defer reader.Release()
    
    if !reader.Next() {
        return nil, errors.New("no record found")
    }
    
    arrowRecord := reader.Record()
    arrowRecord.Retain() // 增加引用计数
    
    // 3. 转换为内部 Record 格式
    return ConvertFromArrowRecord(arrowRecord, schema)
}
```

## 5. 编码优化策略

### 5.1 列式存储优化

#### 5.1.1 数据排列优化
```go
func OptimizeColumnLayout(data []interface{}, dataType schemapb.DataType) []interface{} {
    switch dataType {
    case schemapb.DataType_Int64:
        // 整数类型：差分编码
        return applyDeltaEncoding(data)
        
    case schemapb.DataType_FloatVector:
        // 向量类型：量化编码
        return applyVectorQuantization(data)
        
    case schemapb.DataType_VarChar:
        // 字符串类型：字典编码
        return applyDictionaryEncoding(data)
        
    default:
        return data
    }
}
```

#### 5.1.2 差分编码
```go
func applyDeltaEncoding(data []interface{}) []interface{} {
    if len(data) == 0 {
        return data
    }
    
    encoded := make([]interface{}, len(data))
    encoded[0] = data[0] // 第一个值不变
    
    for i := 1; i < len(data); i++ {
        curr, ok1 := data[i].(int64)
        prev, ok2 := data[i-1].(int64)
        
        if ok1 && ok2 {
            encoded[i] = curr - prev // 存储差值
        } else {
            encoded[i] = data[i] // 非数字类型直接存储
        }
    }
    
    return encoded
}
```

#### 5.1.3 字典编码
```go
type DictionaryEncoder struct {
    dictionary map[string]int32
    values     []string
    nextID     int32
}

func NewDictionaryEncoder() *DictionaryEncoder {
    return &DictionaryEncoder{
        dictionary: make(map[string]int32),
        values:     make([]string, 0),
        nextID:     0,
    }
}

func (de *DictionaryEncoder) Encode(data []interface{}) ([]int32, []string) {
    encoded := make([]int32, len(data))
    
    for i, item := range data {
        str, ok := item.(string)
        if !ok {
            encoded[i] = -1 // 表示 null
            continue
        }
        
        if id, exists := de.dictionary[str]; exists {
            encoded[i] = id
        } else {
            id := de.nextID
            de.dictionary[str] = id
            de.values = append(de.values, str)
            encoded[i] = id
            de.nextID++
        }
    }
    
    return encoded, de.values
}
```

### 5.2 压缩级别策略

#### 5.2.1 自适应压缩级别
```go
type CompressionStrategy struct {
    dataSize     int64
    dataType     schemapb.DataType
    ioLatency    time.Duration
    cpuBudget    float64
}

func (cs *CompressionStrategy) SelectLevel() int {
    // 小数据：高压缩比
    if cs.dataSize < 1024*1024 { // < 1MB
        return zstd.SpeedBetterCompression
    }
    
    // 大数据且 CPU 充足：平衡模式
    if cs.cpuBudget > 0.5 {
        return zstd.SpeedDefault
    }
    
    // 高 I/O 延迟：高压缩比
    if cs.ioLatency > 100*time.Millisecond {
        return zstd.SpeedBetterCompression
    }
    
    // 默认：快速压缩
    return zstd.SpeedFastest
}
```

#### 5.2.2 批量压缩优化
```go
type BatchCompressor struct {
    codec        Codec
    batchSize    int
    maxBatchMem  int64
    currentBatch [][]byte
    currentMem   int64
}

func (bc *BatchCompressor) AddData(data []byte) error {
    if bc.currentMem+int64(len(data)) > bc.maxBatchMem ||
       len(bc.currentBatch) >= bc.batchSize {
        if err := bc.Flush(); err != nil {
            return err
        }
    }
    
    bc.currentBatch = append(bc.currentBatch, data)
    bc.currentMem += int64(len(data))
    
    return nil
}

func (bc *BatchCompressor) Flush() error {
    if len(bc.currentBatch) == 0 {
        return nil
    }
    
    // 合并所有数据
    totalSize := bc.currentMem
    merged := make([]byte, 0, totalSize)
    
    for _, data := range bc.currentBatch {
        merged = append(merged, data...)
    }
    
    // 批量压缩
    compressed := bc.codec.Encode(nil, merged)
    
    // 保存压缩结果
    return bc.saveCompressed(compressed)
}
```

## 6. 性能监控与调优

### 6.1 压缩效果监控

#### 6.1.1 压缩比统计
```go
type CompressionStats struct {
    OriginalSize   int64     // 原始大小
    CompressedSize int64     // 压缩后大小
    CompressionTime time.Duration // 压缩时间
    DecompressionTime time.Duration // 解压时间
}

func (cs *CompressionStats) CompressionRatio() float64 {
    if cs.OriginalSize == 0 {
        return 0
    }
    return float64(cs.CompressedSize) / float64(cs.OriginalSize)
}

func (cs *CompressionStats) CompressionThroughput() float64 {
    if cs.CompressionTime == 0 {
        return 0
    }
    return float64(cs.OriginalSize) / cs.CompressionTime.Seconds()
}
```

#### 6.1.2 实时监控
```go
type CompressionMonitor struct {
    stats    map[string]*CompressionStats
    mutex    sync.RWMutex
    reporter *MetricsReporter
}

func (cm *CompressionMonitor) RecordCompression(
    dataType string, 
    originalSize, compressedSize int64,
    duration time.Duration,
) {
    cm.mutex.Lock()
    defer cm.mutex.Unlock()
    
    if _, exists := cm.stats[dataType]; !exists {
        cm.stats[dataType] = &CompressionStats{}
    }
    
    stats := cm.stats[dataType]
    stats.OriginalSize += originalSize
    stats.CompressedSize += compressedSize
    stats.CompressionTime += duration
    
    // 报告指标
    cm.reporter.ReportCompressionRatio(dataType, stats.CompressionRatio())
    cm.reporter.ReportCompressionThroughput(dataType, stats.CompressionThroughput())
}
```

### 6.2 调优建议

#### 6.2.1 配置参数优化
```yaml
storage:
  compression:
    # ZSTD 压缩级别 (1-22)
    level: 3
    
    # 并发压缩线程数
    concurrency: 4
    
    # 压缩块大小
    blockSize: 1048576  # 1MB
    
    # 字典大小
    dictSize: 65536     # 64KB
    
  encoding:
    # 是否启用差分编码
    enableDeltaEncoding: true
    
    # 字典编码阈值
    dictionaryThreshold: 0.7
    
    # 向量量化精度
    vectorQuantizationBits: 8
```

#### 6.2.2 硬件相关优化
```go
func OptimizeForHardware() CompressionConfig {
    config := CompressionConfig{}
    
    // CPU 核心数
    cpuCount := runtime.NumCPU()
    config.Concurrency = min(cpuCount, 8) // 限制最大并发数
    
    // 内存大小
    var memStats runtime.MemStats
    runtime.ReadMemStats(&memStats)
    
    if memStats.Sys > 8*1024*1024*1024 { // > 8GB
        config.Level = zstd.SpeedBetterCompression
        config.BlockSize = 4 * 1024 * 1024 // 4MB
    } else {
        config.Level = zstd.SpeedDefault
        config.BlockSize = 1 * 1024 * 1024 // 1MB
    }
    
    return config
}
```

## 7. 错误处理与恢复

### 7.1 压缩错误处理

#### 7.1.1 错误检测
```go
func SafeCompress(data []byte, codec Codec) ([]byte, error) {
    defer func() {
        if r := recover(); r != nil {
            log.Error("compression panic", zap.Any("panic", r))
        }
    }()
    
    // 校验输入数据
    if len(data) == 0 {
        return nil, errors.New("empty data")
    }
    
    // 执行压缩
    compressed := codec.Encode(nil, data)
    
    // 验证压缩结果
    if len(compressed) == 0 {
        return nil, errors.New("compression failed")
    }
    
    // 验证解压缩
    decompressed := codec.Decode(nil, compressed)
    if !bytes.Equal(data, decompressed) {
        return nil, errors.New("compression verification failed")
    }
    
    return compressed, nil
}
```

#### 7.1.2 降级策略
```go
type FallbackCompressor struct {
    primary   Codec
    fallback  Codec
    threshold float64 // 压缩比阈值
}

func (fc *FallbackCompressor) Compress(data []byte) ([]byte, error) {
    // 尝试主压缩器
    compressed, err := SafeCompress(data, fc.primary)
    if err != nil {
        log.Warn("primary compression failed, using fallback", zap.Error(err))
        return SafeCompress(data, fc.fallback)
    }
    
    // 检查压缩效果
    ratio := float64(len(compressed)) / float64(len(data))
    if ratio > fc.threshold {
        // 压缩效果不佳，使用备用压缩器
        if fallbackCompressed, err := SafeCompress(data, fc.fallback); err == nil {
            fallbackRatio := float64(len(fallbackCompressed)) / float64(len(data))
            if fallbackRatio < ratio {
                return fallbackCompressed, nil
            }
        }
    }
    
    return compressed, nil
}
```

StorageV2 的数据压缩与编码机制通过多层次的优化策略，在保证数据完整性的前提下，实现了存储空间的最大化利用和 I/O 性能的显著提升，为 Milvus 向量数据库提供了高效的数据存储基础。